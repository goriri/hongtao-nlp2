{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ba380c",
   "metadata": {},
   "source": [
    "# NLP text classification for Hongtao NLP - 2 - training and deployment\n",
    "\n",
    "using huggingface bert-base-chinese, recommended from jackie liu(thanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cee6ace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574fae9d",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d89e3720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                            category\n",
      "0   GCI  万物互联 | 看广云物联如何在云上构建无服务器化的“天匠物联网平台”\n",
      "1   GCI                AIoT 出海部署，雅观智能抢滩“躺赢”\n",
      "2   AIU             OPPO 小布助手，与你智趣相投 | 客户案例\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dataset = pd.read_csv(\"dataset.csv\")\n",
    "dataset.columns =['label','category']\n",
    "print(dataset.head(3))\n",
    "train, test = train_test_split(dataset,test_size=0.25,random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94feb4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size (266, 2), test size(89, 2)\n"
     ]
    }
   ],
   "source": [
    "print (\"train size {}, test size{}\".format(train.shape,test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cd53e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('./data/train.csv',index=False,encoding='utf-8')\n",
    "test.to_csv('./data/test.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44dc6b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import os\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "prefix='hongtao-nlp2'\n",
    "\n",
    "bucket = sess.default_bucket() \n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"train/train.csv\")\n",
    ").upload_file(\"./data/train.csv\")\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"test/test.csv\")\n",
    ").upload_file(\"./data/test.csv\")\n",
    "\n",
    "training_input_path = f's3://{sess.default_bucket()}/{prefix}/train/train.csv'\n",
    "test_input_path = f's3://{sess.default_bucket()}/{prefix}/test/test.csv'\n",
    "\n",
    "#git_config = {'repo': 'https://github.com/huggingface/transformers.git','branch': 'v4.6.1'} # v4.6.1 is referring to the `transformers_version` you use in the estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1688a3-f84b-4f87-92be-babc860e07c9",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c58d854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sagemaker\n",
    "# from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# hyperparameters={'per_device_train_batch_size':4,\n",
    "#                  'per_device_eval_batch_size': 4,\n",
    "#                  'model_name_or_path': 'enriqueyanh/bert_cn', #'roberta-large',\n",
    "#                  'train_file':'/opt/ml/input/data/train/train.csv',\n",
    "#                  'validation_file':'/opt/ml/input/data/test/test.csv',\n",
    "#                  'test_file':'/opt/ml/input/data/test/test.csv',\n",
    "#                  'do_train': True,\n",
    "#                  'do_predict': True,\n",
    "#                  'do_eval': True,\n",
    "#                  'save_total_limit':3,\n",
    "#                  'num_train_epochs': 3,\n",
    "#                  'output_dir': '/opt/ml/model',\n",
    "#                  'num_train_epochs': 10,\n",
    "#                  'learning_rate': 5e-5,\n",
    "#                  'seed': 7,\n",
    "#                  'fp16': False,\n",
    "#                  'eval_steps': 1000,\n",
    "#                  }\n",
    "\n",
    "\n",
    "# # create the Estimato\n",
    "# huggingface_estimator = HuggingFace(\n",
    "#       entry_point='run_glue.py', # script\n",
    "#       source_dir='./', # relative path to example\n",
    "#       instance_type='ml.p3.2xlarge',\n",
    "#       instance_count=1,\n",
    "#       volume_size=50,\n",
    "#       transformers_version='4.6',\n",
    "#       pytorch_version='1.7',\n",
    "#       py_version='py36',\n",
    "#       role=role,\n",
    "#       base_job_name='hongtao-nlp2-bert-cn-epoch10',\n",
    "#       hyperparameters = hyperparameters\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71f57746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# gets role for executing training job\n",
    "role = sagemaker.get_execution_role()\n",
    "hyperparameters = {\n",
    "    'model_name_or_path':'bert-base-chinese',\n",
    "    'output_dir':'/opt/ml/model',\n",
    "    'train_file':'/opt/ml/input/data/train/train.csv',\n",
    "    'validation_file':'/opt/ml/input/data/test/test.csv',\n",
    "    'test_file':'/opt/ml/input/data/test/test.csv',\n",
    "    'do_train': True,\n",
    "    'do_predict': True,\n",
    "    'do_eval': True,\n",
    "    'save_total_limit':3,\n",
    "    'num_train_epochs': 3,\n",
    "    'output_dir': '/opt/ml/model',\n",
    "    'num_train_epochs': 10,\n",
    "    'learning_rate': 5e-5,\n",
    "    'seed': 7,\n",
    "    'fp16': False,\n",
    "    'eval_steps': 1000,\n",
    "    # add your remaining hyperparameters\n",
    "    # more info here https://github.com/huggingface/transformers/tree/v4.17.0/examples/pytorch/text-classification\n",
    "}\n",
    "\n",
    "# git configuration to download our fine-tuning script\n",
    "git_config = {'repo': 'https://github.com/huggingface/transformers.git','branch': 'v4.17.0'}\n",
    "\n",
    "# creates Hugging Face estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point='run_glue.py',\n",
    "    source_dir='./examples/pytorch/text-classification',\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    git_config=git_config,\n",
    "    transformers_version='4.17.0',\n",
    "    pytorch_version='1.10.2',\n",
    "    py_version='py38',\n",
    "    hyperparameters = hyperparameters\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9b2366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-09 14:39:52 Starting - Starting the training job...\n",
      "2022-11-09 14:40:17 Starting - Preparing the instances for trainingProfilerReport-1668004792: InProgress\n",
      ".........\n",
      "2022-11-09 14:41:39 Downloading - Downloading input data...\n",
      "2022-11-09 14:42:16 Training - Downloading the training image...................."
     ]
    }
   ],
   "source": [
    "# starting the train job\n",
    "# huggingface_estimator.fit()\n",
    "huggingface_estimator.fit({'train':training_input_path,'test':test_input_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ef0ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface_estimator.fit({'train':training_input_path,'test':test_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdb30fe",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e35b80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=huggingface_estimator.model_data,  # path to your trained sagemaker model\n",
    "   role=role, # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.6\", # transformers version used\n",
    "   pytorch_version=\"1.7\", # pytorch version used\n",
    "   py_version=\"py36\", # python version of the DLC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bb14b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type=\"ml.g4dn.xlarge\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aac738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# example request, you always need to define \"inputs\"\n",
    "data = {\n",
    "   \"inputs\": \"我们从今年才开始给文章打标签，如果目前的样本量小\"\n",
    "}\n",
    "\n",
    "# request\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63c5651",
   "metadata": {},
   "source": [
    "## ONLY for existed endpoint, create new Predictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcf0ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.predictor import Predictor\n",
    "#predictor = Predictor()\n",
    "from sagemaker.serializers import NumpySerializer\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import NumpyDeserializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "#import sagemaker.serializers.\n",
    "###\n",
    "#'please change to your endpoint_name'\n",
    "###\n",
    "endpoint_name = 'huggingface-pytorch-inference-2022-09-27-08-59-15-528'\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")\n",
    "\n",
    "data = {\n",
    "   \"inputs\": \"亚马逊云计算AWS入门\"\n",
    "}\n",
    "\n",
    "# request\n",
    "predictor.predict(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a468b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
